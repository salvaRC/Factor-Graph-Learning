{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from examples.factors import accuracies, propensities\n",
    "from examples.prediction_and_evaluation import pred_and_eval_gen_model, eval_majority_vote\n",
    "from examples.utils import change_labels\n",
    "from factor_graph import FactorGraph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing the implemented factor graph against Snorkel (a latent MRF model)\n",
    "\n",
    "## The data used consists of:\n",
    " - labels Y for the created task of discriminating professors from teachers in the Bias in Bios dataset\n",
    " - 99 selected labeling functions, usable for a standard data programming pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train_supervised(label_matrix, Y_true, lf_prop=True, n_epoch=25, lr=0.1, gibbs_samples=10, batch_size=250):\n",
    "    start_t = time.time()\n",
    "    n_LFs = label_matrix.shape[1]\n",
    "    \"\"\" Get polarities of each LF, ASSUMPTION: Each LF only votes for ONE label, and abstains otherwise\"\"\"\n",
    "    polarities = [(0, pol) for pol in np.sign(np.sum(label_matrix, axis=0))]\n",
    "    \"\"\" In the supervised case, the data fed into the PGM Learning will just be all concatenated \"\"\"\n",
    "    observations = np.concatenate((Y_true.reshape((-1, 1)), label_matrix), axis=1)\n",
    "    \"\"\" Create a MRF with fully observed variables\"\"\"\n",
    "    potentials = [(accuracies, n_LFs)]  # (function, #outputs), e.g. we have n_LFs accuracies to model\n",
    "    if lf_prop:\n",
    "        potentials += [(propensities, n_LFs)]\n",
    "    lm = FactorGraph(n_vars=n_LFs+1, polarities=[(1, -1)] + list(polarities), potentials=potentials)\n",
    "    lm.fit(observations, lr=lr, n_epochs=n_epoch, batch_size=batch_size, gibbs_samples=gibbs_samples, verbose=False)\n",
    "    \"\"\" Evaluate the learned generative model \"\"\"\n",
    "    stat, probs = pred_and_eval_gen_model(lm, observations, Y_true, version=99, abst=0, verbose=True, print_MV=False,\n",
    "                                          eps=0.0, return_preds=True, coverage_stats=False, neg_label=-1, pos_label=1)\n",
    "    duration = time.time() - start_t\n",
    "    print(f\"Time needed by generative model: {duration}\")\n",
    "    # Will train the downstream classifier:\n",
    "    # stat_cl = train_and_eval_classifier(Xtrain, Xtest, probs, Ytest, label_matrix, library='torch',\n",
    "    #                                    optim='Adam', devicestring=device, epochs=250, print_step=505)\n",
    "    return lm, stat, probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train_snorkel(label_matrix, Y_true, n_epoch=1000, lr=0.1):\n",
    "    from snorkel.labeling.model import LabelModel\n",
    "    # LABEL MODEL\n",
    "    start_t = time.time()\n",
    "    \"\"\" Snorkel requires abstention label to be -1...\"\"\"\n",
    "    label_matrix, Y_true = change_labels(label_matrix, Y_true, new_label=-1, old_label=0)\n",
    "    \"\"\" Train latent label model from Snorkel \"\"\"\n",
    "    lm = LabelModel(cardinality=2)\n",
    "    lm.fit(label_matrix, n_epochs=n_epoch, seed=77, lr=lr)\n",
    "    \"\"\" Evaluate the learned generative model \"\"\"\n",
    "    stat, probs = pred_and_eval_gen_model(lm, label_matrix, Y_true, abst=-1, verbose=True,\n",
    "                                          print_MV=False, eps=0.0, neg_label=0, pos_label=+1,\n",
    "                                          return_preds=True, version=10, coverage_stats=False)\n",
    "\n",
    "    duration = time.time() - start_t\n",
    "    print(f\"Time needed by Snorkel's generative model: {duration}\")\n",
    "    # Will train the downstream classifier:\n",
    "    # stat_cl = train_and_eval_classifier(Xtrain, Xtest, probs, Ytest, label_matrix, library='torch',\n",
    "    #                                    optim='Adam', devicestring=device, epochs=250, print_step=505)\n",
    "    return lm, stat, probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "seed = 77\n",
    "n_runs = 5\n",
    "data = np.load(\"../data/professor_vs_teacher_99LFs.npz\")\n",
    "L_arr, Ytrain = data[\"L\"], data[\"Y\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------- MAJORITY VOTE STATS --------------------------------------------------\n",
      "MV on all samples with  99 LFs\n",
      "Majority vote stats:\n",
      "Accuracy:0.754 | Precision:0.771 | Recall:0.717 | F1 score:0.743 | AUC:0.796 | Log loss:5.506 | Brier:0.917 | Coverage:1.000 | MSE, MAE:0.917, 0.751\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------- MAJORITY VOTE STATS --------------------------------------------------\")\n",
    "print(\"MV on all samples with \", L_arr.shape[1], \"LFs\")\n",
    "eval_majority_vote(L_arr, Ytrain, abst=0, MV_policy='random')\n",
    "print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "# PRINT LF descriptions: [print(d) for d in descr]\n",
    "lfprop = False\n",
    "n_samples, nlf = L_arr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Supervised (ours)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.790 | Precision:0.758 | Recall:0.848 | F1 score:0.800 | AUC:0.888 | Log loss:1.065 | Brier:0.944 | Coverage:1.000 | MSE, MAE:0.944, 0.735\n",
      "Time needed by generative model: 4.383999824523926\n",
      "Accuracy:0.781 | Precision:0.764 | Recall:0.806 | F1 score:0.784 | AUC:0.875 | Log loss:1.803 | Brier:0.931 | Coverage:1.000 | MSE, MAE:0.931, 0.730\n",
      "Time needed by generative model: 11.266000509262085\n",
      "Accuracy:0.791 | Precision:0.757 | Recall:0.850 | F1 score:0.801 | AUC:0.883 | Log loss:1.795 | Brier:0.939 | Coverage:1.000 | MSE, MAE:0.939, 0.729\n",
      "Time needed by generative model: 11.008025407791138\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.1, n_epoch=10)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.1, n_epoch=25)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.1, n_epoch=25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.778 | Precision:0.738 | Recall:0.855 | F1 score:0.792 | AUC:0.887 | Log loss:1.069 | Brier:0.947 | Coverage:1.000 | MSE, MAE:0.947, 0.735\n",
      "Time needed by generative model: 2.7640011310577393\n",
      "Accuracy:0.786 | Precision:0.752 | Recall:0.847 | F1 score:0.797 | AUC:0.883 | Log loss:1.803 | Brier:0.936 | Coverage:1.000 | MSE, MAE:0.936, 0.729\n",
      "Time needed by generative model: 7.083952188491821\n",
      "Accuracy:0.779 | Precision:0.739 | Recall:0.856 | F1 score:0.793 | AUC:0.887 | Log loss:0.664 | Brier:0.958 | Coverage:1.000 | MSE, MAE:0.958, 0.748\n",
      "Time needed by generative model: 14.245006799697876\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.1, n_epoch=10, gibbs_samples=5)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.1, n_epoch=25, gibbs_samples=5)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.01, n_epoch=50, gibbs_samples=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.786 | Precision:0.755 | Recall:0.843 | F1 score:0.796 | AUC:0.889 | Log loss:0.658 | Brier:0.941 | Coverage:1.000 | MSE, MAE:0.941, 0.742\n",
      "Time needed by generative model: 7.099032163619995\n",
      "Accuracy:0.776 | Precision:0.738 | Recall:0.850 | F1 score:0.790 | AUC:0.887 | Log loss:0.525 | Brier:0.985 | Coverage:1.000 | MSE, MAE:0.985, 0.766\n",
      "Time needed by generative model: 27.555073499679565\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.01, n_epoch=50, gibbs_samples=1)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.003, n_epoch=100, gibbs_samples=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Snorkel\n",
    "### Note that this is the newer, faster matrix completion snorkel. (the old snorkel using SGD+MLE is slower than ours above)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.769 | Precision:0.718 | Recall:0.878 | F1 score:0.790 | AUC:0.880 | Log loss:0.678 | Brier:0.159 | Coverage:1.000 | MSE, MAE:0.159, 0.275\n",
      "Time needed by Snorkel's generative model: 1.7589950561523438\n",
      "Accuracy:0.769 | Precision:0.718 | Recall:0.878 | F1 score:0.790 | AUC:0.880 | Log loss:0.678 | Brier:0.159 | Coverage:1.000 | MSE, MAE:0.159, 0.275\n",
      "Time needed by Snorkel's generative model: 1.7600352764129639\n",
      "Accuracy:0.769 | Precision:0.718 | Recall:0.878 | F1 score:0.790 | AUC:0.880 | Log loss:0.678 | Brier:0.159 | Coverage:1.000 | MSE, MAE:0.159, 0.275\n",
      "Time needed by Snorkel's generative model: 1.8869962692260742\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_snorkel(L_arr, Ytrain, lr=0.01, n_epoch=1000)\n",
    "_, _, _ = train_snorkel(L_arr, Ytrain, lr=0.01, n_epoch=1000)\n",
    "_, _, _ = train_snorkel(L_arr, Ytrain, lr=0.1, n_epoch=1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from examples.factors import accuracies, propensities\n",
    "from examples.prediction_and_evaluation import pred_and_eval_gen_model, eval_majority_vote\n",
    "from examples.utils import change_labels\n",
    "from factor_graph import FactorGraph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing the implemented factor graph against Snorkel (a latent MRF model)\n",
    "\n",
    "## The data used consists of:\n",
    " - labels Y for the created task of discriminating professors from teachers in the Bias in Bios dataset\n",
    " - 99 selected labeling functions, usable for a standard data programming pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def train_supervised(label_matrix, Y_true, lf_prop=True, n_epoch=25, lr=0.1, gibbs_samples=10):\n",
    "    start_t = time.time()\n",
    "    n_LFs = label_matrix.shape[1]\n",
    "    \"\"\" Get polarities of each LF, ASSUMPTION: Each LF only votes for ONE label, and abstains otherwise\"\"\"\n",
    "    polarities = np.sign(np.sum(label_matrix, axis=0))\n",
    "    \"\"\" In the supervised case, the data fed into the PGM Learning will just be all concatenated \"\"\"\n",
    "    observations = np.concatenate((Y_true.reshape((-1, 1)), label_matrix), axis=1)\n",
    "    \"\"\" Create a MRF with fully observed variables\"\"\"\n",
    "    potentials = [(accuracies, n_LFs)]\n",
    "    if lf_prop:\n",
    "        potentials += [(propensities, n_LFs)]\n",
    "    lm = FactorGraph(n_vars=n_LFs+1, polarities=[-1] + list(polarities), potentials=potentials)\n",
    "    lm.fit(observations, lr=lr, n_epochs=n_epoch, batch_size=250, gibbs_samples=gibbs_samples, verbose=False)\n",
    "    \"\"\" Evaluate the learned generative model \"\"\"\n",
    "    stat, probs = pred_and_eval_gen_model(lm, observations, Y_true, version=99, abst=0, verbose=True, print_MV=False,\n",
    "                                          eps=0.0, return_preds=True, coverage_stats=False, add_prefix=\"\")\n",
    "    duration = time.time() - start_t\n",
    "    print(f\"Time needed by generative model: {duration}\")\n",
    "    # Will train the downstream classifier:\n",
    "    # stat_cl = train_and_eval_classifier(Xtrain, Xtest, probs, Ytest, label_matrix, library='torch',\n",
    "    #                                    optim='Adam', devicestring=device, epochs=250, print_step=505)\n",
    "    return lm, stat, probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train_snorkel(label_matrix, Y_true, n_epoch=1000, lr=0.1):\n",
    "    from snorkel.labeling.model import LabelModel\n",
    "    # LABEL MODEL\n",
    "    start_t = time.time()\n",
    "    \"\"\" Snorkel requires abstention label to be -1...\"\"\"\n",
    "    label_matrix, Y_true = change_labels(label_matrix, Y_true, new_label=-1, old_label=0)\n",
    "    \"\"\" Train latent label model from Snorkel \"\"\"\n",
    "    lm = LabelModel(cardinality=2)\n",
    "    lm.fit(label_matrix, n_epochs=n_epoch, seed=77, lr=lr)\n",
    "    \"\"\" Evaluate the learned generative model \"\"\"\n",
    "    stat, probs = pred_and_eval_gen_model(lm, label_matrix, Y_true, abst=-1, verbose=True,\n",
    "                                          print_MV=False, eps=0.0, MV_policy=\"random\",\n",
    "                                          return_preds=True, version=10, coverage_stats=False)\n",
    "\n",
    "    duration = time.time() - start_t\n",
    "    print(f\"Time needed by Snorkel's generative model: {duration}\")\n",
    "    # Will train the downstream classifier:\n",
    "    # stat_cl = train_and_eval_classifier(Xtrain, Xtest, probs, Ytest, label_matrix, library='torch',\n",
    "    #                                    optim='Adam', devicestring=device, epochs=250, print_step=505)\n",
    "    return lm, stat, probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "seed = 77\n",
    "n_runs = 5\n",
    "data = np.load(\"../data/professor_vs_teacher_99LFs.npz\")\n",
    "L_arr, Ytrain = data[\"L\"], data[\"Y\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------- MAJORITY VOTE STATS --------------------------------------------------\n",
      "MV on all samples with  99 LFs\n",
      "Majority vote stats:\n",
      "Accuracy:0.753 | Precision:0.768 | Recall:0.718 | F1 score:0.742 | AUC:0.796 | Log loss:5.506 | Brier:0.917 | Coverage:1.000 | MSE, MAE:0.917, 0.751\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------- MAJORITY VOTE STATS --------------------------------------------------\")\n",
    "print(\"MV on all samples with \", L_arr.shape[1], \"LFs\")\n",
    "eval_majority_vote(L_arr, Ytrain, abst=0, MV_policy='random')\n",
    "print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "# PRINT LF descriptions: [print(d) for d in descr]\n",
    "lfprop = False\n",
    "n_samples, nlf = L_arr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Supervised (ours)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.750 | Precision:0.692 | Recall:0.892 | F1 score:0.779 | AUC:0.888 | Log loss:1.579 | Brier:1.072 | Coverage:1.000 | MSE, MAE:1.072, 0.755\n",
      "Time needed by generative model: 6.288998126983643\n",
      "Accuracy:0.754 | Precision:0.696 | Recall:0.892 | F1 score:0.782 | AUC:0.881 | Log loss:2.864 | Brier:1.069 | Coverage:1.000 | MSE, MAE:1.069, 0.750\n",
      "Time needed by generative model: 13.827793836593628\n",
      "Accuracy:0.750 | Precision:0.692 | Recall:0.889 | F1 score:0.779 | AUC:0.881 | Log loss:2.856 | Brier:1.069 | Coverage:1.000 | MSE, MAE:1.069, 0.750\n",
      "Time needed by generative model: 13.001982688903809\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.1, n_epoch=10)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.1, n_epoch=25)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.1, n_epoch=25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.758 | Precision:0.700 | Recall:0.892 | F1 score:0.785 | AUC:0.891 | Log loss:1.453 | Brier:1.057 | Coverage:1.000 | MSE, MAE:1.057, 0.750\n",
      "Time needed by generative model: 3.264031410217285\n",
      "Accuracy:0.760 | Precision:0.703 | Recall:0.895 | F1 score:0.787 | AUC:0.886 | Log loss:2.593 | Brier:1.052 | Coverage:1.000 | MSE, MAE:1.052, 0.745\n",
      "Time needed by generative model: 7.958951234817505\n",
      "Accuracy:0.771 | Precision:0.717 | Recall:0.889 | F1 score:0.794 | AUC:0.893 | Log loss:0.842 | Brier:1.062 | Coverage:1.000 | MSE, MAE:1.062, 0.758\n",
      "Time needed by generative model: 15.33894395828247\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.1, n_epoch=10, gibbs_samples=5)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.1, n_epoch=25, gibbs_samples=5)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.01, n_epoch=50, gibbs_samples=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.788 | Precision:0.756 | Recall:0.843 | F1 score:0.797 | AUC:0.889 | Log loss:0.658 | Brier:0.941 | Coverage:1.000 | MSE, MAE:0.941, 0.742\n",
      "Time needed by generative model: 8.038997888565063\n",
      "Accuracy:0.772 | Precision:0.717 | Recall:0.891 | F1 score:0.795 | AUC:0.893 | Log loss:0.617 | Brier:1.075 | Coverage:1.000 | MSE, MAE:1.075, 0.771\n",
      "Time needed by generative model: 30.81801724433899\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.01, n_epoch=50, gibbs_samples=1)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, lf_prop=lfprop, lr=0.003, n_epoch=100, gibbs_samples=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Snorkel\n",
    "### Note that this is the newer, faster matrix completion snorkel. (the old snorkel using SGD+MLE is slower than ours above)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.769 | Precision:0.718 | Recall:0.878 | F1 score:0.790 | AUC:0.880 | Log loss:0.678 | Brier:0.159 | Coverage:1.000 | MSE, MAE:0.159, 0.275\n",
      "Time needed by Snorkel's generative model: 2.0525929927825928\n",
      "Accuracy:0.769 | Precision:0.718 | Recall:0.878 | F1 score:0.790 | AUC:0.880 | Log loss:0.678 | Brier:0.159 | Coverage:1.000 | MSE, MAE:0.159, 0.275\n",
      "Time needed by Snorkel's generative model: 1.8980004787445068\n",
      "Accuracy:0.769 | Precision:0.718 | Recall:0.878 | F1 score:0.790 | AUC:0.880 | Log loss:0.678 | Brier:0.159 | Coverage:1.000 | MSE, MAE:0.159, 0.275\n",
      "Time needed by Snorkel's generative model: 1.8270001411437988\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_snorkel(L_arr, Ytrain, lr=0.01, n_epoch=1000)\n",
    "_, _, _ = train_snorkel(L_arr, Ytrain, lr=0.01, n_epoch=1000)\n",
    "_, _, _ = train_snorkel(L_arr, Ytrain, lr=0.1, n_epoch=1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
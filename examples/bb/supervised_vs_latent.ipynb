{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from examples.prediction_and_evaluation import pred_and_eval_gen_model, eval_majority_vote\n",
    "from examples.utils import change_labels\n",
    "from factor_graph import FactorGraph\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing the implemented factor graph against Snorkel (a latent MRF model)\n",
    "\n",
    "## The data used consists of:\n",
    " - labels Y for the created task of discriminating professors from teachers in the Bias in Bios dataset\n",
    " - 99 selected labeling functions, usable for a standard data programming framework"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def train_supervised(label_matrix, Y_true, dependencies, lf_prop=True, n_epoch=25, lr=0.1):\n",
    "    start_t = time.time()\n",
    "    \"\"\" Get polarities of each LF, ASSUMPTION: Each LF only votes for ONE label, and abstains otherwise\"\"\"\n",
    "    polarities = np.sign(np.sum(label_matrix, axis=0))\n",
    "    \"\"\" In the supervised case, the data fed into the PGM Learning will just be all concatenated \"\"\"\n",
    "    observations = np.concatenate((Y_true.reshape((-1, 1)), label_matrix), axis=1)\n",
    "    \"\"\" Create a MRF with fully observed variables\"\"\"\n",
    "    lm = FactorGraph(n_LFs=label_matrix.shape[1], LF_polarities=polarities, deps=dependencies)\n",
    "    lm.fit(observations, lr=lr, n_epochs=n_epoch, batch_size=250)\n",
    "    \"\"\" Evaluate the learned generative model \"\"\"\n",
    "    stat, probs = pred_and_eval_gen_model(lm, observations, Y_true, version=99, abst=0, verbose=True, print_MV=False,\n",
    "                                          eps=0.0, return_preds=True, coverage_stats=False, add_prefix=\"\")\n",
    "    duration = time.time() - start_t\n",
    "    print(f\"Time needed by generative model: {duration}\")\n",
    "    # Will train the downstream classifier:\n",
    "    # stat_cl = train_and_eval_classifier(Xtrain, Xtest, probs, Ytest, label_matrix, library='torch',\n",
    "    #                                    optim='Adam', devicestring=device, epochs=250, print_step=505)\n",
    "    return lm, stat, probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def train_snorkel(label_matrix, Y_true, n_epoch=1000, lr=0.1):\n",
    "    from snorkel.labeling.model import LabelModel\n",
    "    # LABEL MODEL\n",
    "    start_t = time.time()\n",
    "    \"\"\" Snorkel requires abstention label to be -1...\"\"\"\n",
    "    label_matrix, Y_true = change_labels(label_matrix, Y_true, new_label=-1, old_label=0)\n",
    "    \"\"\" Train latent label model from Snorkel \"\"\"\n",
    "    lm = LabelModel(cardinality=2)\n",
    "    lm.fit(label_matrix, n_epochs=n_epoch, seed=77, lr=lr)\n",
    "    \"\"\" Evaluate the learned generative model \"\"\"\n",
    "    stat, probs = pred_and_eval_gen_model(lm, label_matrix, Y_true, abst=-1, verbose=True,\n",
    "                                          print_MV=False, eps=0.0, MV_policy=\"random\",\n",
    "                                          return_preds=True, version=10, coverage_stats=False)\n",
    "\n",
    "    duration = time.time() - start_t\n",
    "    print(f\"Time needed by Snorkel's generative model: {duration}\")\n",
    "    # Will train the downstream classifier:\n",
    "    # stat_cl = train_and_eval_classifier(Xtrain, Xtest, probs, Ytest, label_matrix, library='torch',\n",
    "    #                                    optim='Adam', devicestring=device, epochs=250, print_step=505)\n",
    "    return lm, stat, probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "seed = 77\n",
    "n_runs = 5\n",
    "data = np.load(\"../data/professor_vs_teacher_99LFs.npz\")\n",
    "L_arr, Ytrain = data[\"L\"], data[\"Y\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------- MAJORITY VOTE STATS --------------------------------------------------\n",
      "MV on all samples with  99 LFs\n",
      "Majority vote stats:\n",
      "Accuracy:0.754 | Precision:0.772 | Recall:0.713 | F1 score:0.742 | AUC:0.796 | Log loss:5.506 | Brier:0.917 | Coverage:1.000 | MSE, MAE:0.917, 0.751\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------- MAJORITY VOTE STATS --------------------------------------------------\")\n",
    "print(\"MV on all samples with \", L_arr.shape[1], \"LFs\")\n",
    "eval_majority_vote(L_arr, Ytrain, abst=0, MV_policy='random')\n",
    "print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "# PRINT LF descriptions: [print(d) for d in descr]\n",
    "lfprop = False\n",
    "n_samples, nlf = L_arr.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Supervised (ours)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0...\n",
      "Accuracy:0.787 | Precision:0.754 | Recall:0.845 | F1 score:0.797 | AUC:0.890 | Log loss:1.182 | Brier:0.949 | Coverage:1.000 | MSE, MAE:0.949, 0.726\n",
      "Time needed by generative model: 59.90506148338318\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_supervised(L_arr, Ytrain, [],  lf_prop=lfprop, lr=0.1, n_epoch=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0...\n",
      "Accuracy:0.787 | Precision:0.763 | Recall:0.828 | F1 score:0.794 | AUC:0.883 | Log loss:1.142 | Brier:0.938 | Coverage:1.000 | MSE, MAE:0.938, 0.730\n",
      "Time needed by generative model: 68.06458353996277\n",
      "Epoch 0...\n",
      "Accuracy:0.783 | Precision:0.760 | Recall:0.820 | F1 score:0.789 | AUC:0.876 | Log loss:1.880 | Brier:0.947 | Coverage:1.000 | MSE, MAE:0.947, 0.730\n",
      "Time needed by generative model: 150.51205468177795\n",
      "Epoch 0...\n",
      "Accuracy:0.781 | Precision:0.736 | Recall:0.870 | F1 score:0.797 | AUC:0.886 | Log loss:2.385 | Brier:0.987 | Coverage:1.000 | MSE, MAE:0.987, 0.727\n",
      "Time needed by generative model: 159.4011058807373\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_supervised(L_arr, Ytrain, [],  lf_prop=lfprop, lr=0.1, n_epoch=10)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, [], lf_prop=lfprop, lr=0.1, n_epoch=25)\n",
    "_, _, _ = train_supervised(L_arr, Ytrain, [], lf_prop=lfprop, lr=0.1, n_epoch=25)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Snorkel\n",
    "### Note that this is the newer, faster snorkel. (the old snorkel using SGD+MLE is similarly slow or slower)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.769 | Precision:0.718 | Recall:0.878 | F1 score:0.790 | AUC:0.880 | Log loss:0.678 | Brier:0.159 | Coverage:1.000 | MSE, MAE:0.159, 0.275\n",
      "Time needed by Snorkel's generative model: 3.0689585208892822\n",
      "Accuracy:0.769 | Precision:0.718 | Recall:0.878 | F1 score:0.790 | AUC:0.880 | Log loss:0.678 | Brier:0.159 | Coverage:1.000 | MSE, MAE:0.159, 0.275\n",
      "Time needed by Snorkel's generative model: 2.7420010566711426\n",
      "Accuracy:0.769 | Precision:0.718 | Recall:0.878 | F1 score:0.790 | AUC:0.880 | Log loss:0.678 | Brier:0.159 | Coverage:1.000 | MSE, MAE:0.159, 0.275\n",
      "Time needed by Snorkel's generative model: 2.7009992599487305\n"
     ]
    }
   ],
   "source": [
    "_, _, _ = train_snorkel(L_arr, Ytrain, lr=0.01, n_epoch=1000)\n",
    "_, _, _ = train_snorkel(L_arr, Ytrain, lr=0.01, n_epoch=1000)\n",
    "_, _, _ = train_snorkel(L_arr, Ytrain, lr=0.1, n_epoch=1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}